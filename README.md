##XAI-Phy

LLM Insight EngineThe LLM Insight Engine is a sophisticated framework designed to enhance the explainability and interpretability of Large Language Models (LLMs). It addresses the "black box" problem by providing clear, intuitive visualizations of a model's internal reasoning process.The engine simulates tokens as particles in a 2D space, governed by semantic and contextual forces derived from the model's embeddings and attention mechanisms. The result is a dynamic "reasoning map" that offers a powerful tool for analyzing, debugging, and improving the reliability of language models.An example visualization generated by the LLM Insight Engine.Table of ContentsFeaturesHow It WorksGetting StartedPrerequisitesInstallationUsageContributingLicenseAcknowledgmentsFeaturesAI Explainability: Transforms abstract model states into clear, visual reasoning maps.Dual-Force Model: Simulates token interactions using both semantic similarity and contextual attention forces.Hallucination Detection: Provides a mechanism to visually inspect and identify logical inconsistencies or factual errors in model outputs.Hierarchical Analysis: Capable of generating high-level "Satellite Views" of entire documents and detailed "Street Views" of individual sentences.Extensible Framework: Built with a modular structure that is easy to extend and integrate into other MLOps pipelines.How It WorksThe engine's methodology is rooted in a physics-based simulation that demystifies a model's internal logic:Tokenization & Embedding: The input text is tokenized, and embeddings are extracted from a specified transformer model.Force Calculation: Two primary forces are calculated for each token pair:Semantic Force: An attractive or repulsive force based on the cosine similarity of token embeddings. Similar tokens attract; dissimilar ones repel.Contextual Attention Force: An attractive force derived from the model's self-attention matrix, linking tokens that are contextually relevant to each other.Simulation: The tokens (as particles) are placed in a 2D environment. Over a series of iterations, their positions are updated based on the net forces acting upon them, eventually reaching a stable state.Visualization: The final particle positions are rendered as a 2D plot, revealing the underlying structure of the model's reasoning. Clusters of particles and the vectors connecting them illustrate the relationships the model has identified.Getting StartedTo get a local copy up and running, follow these steps.PrerequisitesPython 3.7+pip for package managementInstallationClone the repository:git clone [https://github.com/Shakthi-lakmalMSA/XAI-Phy.git](https://github.com/Shakthi-lakmalMSA/XAI-Phy.git)
cd XAI-Phy

Create and activate a virtual environment (recommended):python -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`

Install the required dependencies:pip install -r requirements.txt

UsageThe core logic is accessible through the InsightEngine class. You can import and use it in your own scripts for detailed analysis.Example:from src.engine import InsightEngine
from src.visualization import visualize_simulation

# 1. Initialize the engine with a model
engine = InsightEngine(model_name='bert-base-uncased')

# 2. Analyze a sentence
text = "The quick brown fox jumps over the a lazy dog."
simulation_data = engine.analyze_sentence(text)

# 3. Visualize the results
visualize_simulation(
    simulation_data['final_positions'],
    simulation_data['tokens'],
    simulation_data['attention_matrix'],
    'output.png'
)

print("Analysis complete. Visualization saved to output.png")

For more detailed examples, including the hierarchical analysis of longer documents, please see the notebooks in the examples/ directory.ContributingContributions are welcome and greatly appreciated. To contribute:Fork the Project.Create your Feature Branch (git checkout -b feature/NewFeature).Commit your Changes (git commit -m 'Add some NewFeature').Push to the Branch (git push origin feature/NewFeature).Open a Pull Request.Please make sure to update tests as appropriate.LicenseDistributed under the MIT License. See LICENSE.txt for more information.AcknowledgmentsThis project relies on the excellent work of the Hugging Face team for their transformers library.The simulation approach is inspired by force-directed graph drawing algorithms.PresentationFor a detailed walkthrough of this project, please view the presentation from the Microsoft Student Ambassadors program:View Presentation
